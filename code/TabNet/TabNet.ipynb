{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_tabnet.tab_model import TabNetRegressor, TabNetClassifier\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import wandb\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/opt/ml/input/data/'\n",
    "train_data_path = os.path.join(data_dir, 'train_data.csv')\n",
    "test_data_path = os.path.join(data_dir, 'test_data.csv') \n",
    "df = pd.read_csv(train_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering_base(df):\n",
    "    \n",
    "    df['datetime'] = pd.to_datetime(df['Timestamp'])\n",
    "    df['elapsed'] = df.groupby(['userID','testId'])['datetime'].transform(lambda x: x.diff().fillna(pd.Timedelta(seconds=0)))\n",
    "    df['elapsed'] = df['elapsed'].apply(lambda x: x.total_seconds())\n",
    "    \n",
    "    #유저별 시퀀스를 고려하기 위해 아래와 같이 정렬\n",
    "    df.sort_values(by=['userID','Timestamp'], inplace=True)\n",
    "    \n",
    "    #유저들의 문제 풀이수, 정답 수, 정답률을 시간순으로 누적해서 계산\n",
    "    df['user_correct_answer'] = df.groupby('userID')['answerCode'].transform(lambda x: x.cumsum().shift(1))\n",
    "    df['user_total_answer'] = df.groupby('userID')['answerCode'].cumcount()\n",
    "    df['user_acc'] = df['user_correct_answer']/df['user_total_answer']\n",
    "    df.fillna(0, inplace = True)\n",
    "\n",
    "    # testId와 KnowledgeTag의 전체 정답률은 한번에 계산\n",
    "    # 아래 데이터는 제출용 데이터셋에 대해서도 재사용\n",
    "    correct_t = df.groupby(['testId'])['answerCode'].agg(['mean', 'sum'])\n",
    "    correct_t.columns = [\"test_mean\", 'test_sum']\n",
    "    correct_k = df.groupby(['KnowledgeTag'])['answerCode'].agg(['mean', 'sum'])\n",
    "    correct_k.columns = [\"tag_mean\", 'tag_sum']\n",
    "\n",
    "    df = pd.merge(df, correct_t, on=['testId'], how=\"left\")\n",
    "    df = pd.merge(df, correct_k, on=['KnowledgeTag'], how=\"left\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def elo(df):\n",
    "    def get_new_theta(is_good_answer, beta, left_asymptote, theta, nb_previous_answers):\n",
    "        return theta + learning_rate_theta(nb_previous_answers) * (\n",
    "            is_good_answer - probability_of_good_answer(theta, beta, left_asymptote)\n",
    "        )\n",
    "\n",
    "    def get_new_beta(is_good_answer, beta, left_asymptote, theta, nb_previous_answers):\n",
    "        return beta - learning_rate_beta(nb_previous_answers) * (\n",
    "            is_good_answer - probability_of_good_answer(theta, beta, left_asymptote)\n",
    "        )\n",
    "\n",
    "    def learning_rate_theta(nb_answers):\n",
    "        return max(0.3 / (1 + 0.01 * nb_answers), 0.04)\n",
    "\n",
    "    def learning_rate_beta(nb_answers):\n",
    "        return 1 / (1 + 0.05 * nb_answers)\n",
    "\n",
    "    def probability_of_good_answer(theta, beta, left_asymptote):\n",
    "        return left_asymptote + (1 - left_asymptote) * sigmoid(theta - beta)\n",
    "\n",
    "    def sigmoid(x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def estimate_parameters(answers_df, granularity_feature_name=\"assessmentItemID\"):\n",
    "        item_parameters = {\n",
    "            granularity_feature_value: {\"beta\": 0, \"nb_answers\": 0}\n",
    "            for granularity_feature_value in np.unique(\n",
    "                answers_df[granularity_feature_name]\n",
    "            )\n",
    "        }\n",
    "        student_parameters = {\n",
    "            student_id: {\"theta\": 0, \"nb_answers\": 0}\n",
    "            for student_id in np.unique(answers_df.userID)\n",
    "        }\n",
    "\n",
    "        print(\"Parameter estimation is starting...\", flush=True)\n",
    "\n",
    "        for student_id, item_id, left_asymptote, answered_correctly in tqdm(\n",
    "            zip(\n",
    "                answers_df.userID.values,\n",
    "                answers_df[granularity_feature_name].values,\n",
    "                answers_df.left_asymptote.values,\n",
    "                answers_df.answerCode.values,\n",
    "            ),\n",
    "            total=len(answers_df),\n",
    "        ):\n",
    "            theta = student_parameters[student_id][\"theta\"]\n",
    "            beta = item_parameters[item_id][\"beta\"]\n",
    "\n",
    "            item_parameters[item_id][\"beta\"] = get_new_beta(\n",
    "                answered_correctly,\n",
    "                beta,\n",
    "                left_asymptote,\n",
    "                theta,\n",
    "                item_parameters[item_id][\"nb_answers\"],\n",
    "            )\n",
    "            student_parameters[student_id][\"theta\"] = get_new_theta(\n",
    "                answered_correctly,\n",
    "                beta,\n",
    "                left_asymptote,\n",
    "                theta,\n",
    "                student_parameters[student_id][\"nb_answers\"],\n",
    "            )\n",
    "\n",
    "            item_parameters[item_id][\"nb_answers\"] += 1\n",
    "            student_parameters[student_id][\"nb_answers\"] += 1\n",
    "\n",
    "        print(f\"Theta & beta estimations on {granularity_feature_name} are completed.\")\n",
    "        return student_parameters, item_parameters\n",
    "\n",
    "    def gou_func(theta, beta):\n",
    "        return 1 / (1 + np.exp(-(theta - beta)))\n",
    "\n",
    "    df[\"left_asymptote\"] = 0\n",
    "\n",
    "    print(f\"Dataset of shape {df.shape}\")\n",
    "    print(f\"Columns are {list(df.columns)}\")\n",
    "\n",
    "    student_parameters, item_parameters = estimate_parameters(df)\n",
    "\n",
    "    prob = [\n",
    "        gou_func(student_parameters[student][\"theta\"], item_parameters[item][\"beta\"])\n",
    "        for student, item in zip(df.userID.values, df.assessmentItemID.values)\n",
    "    ]\n",
    "\n",
    "    df[\"elo\"] = prob\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "def custom_split_and_encoding(df, ratio=0.7):\n",
    "    categorical_columns = ['userID', 'assessmentItemID', 'testId', 'KnowledgeTag']\n",
    "    categorical_dims =  {}\n",
    "    \n",
    "    for col in categorical_columns:\n",
    "        le = LabelEncoder()\n",
    "        df[col] = le.fit_transform(df[col].values)\n",
    "        categorical_dims[col] = len(le.classes_)\n",
    "    \n",
    "    users = list(zip(df['userID'].value_counts().index, df['userID'].value_counts()))\n",
    "    random.shuffle(users)\n",
    "\n",
    "    max_train_data_len = ratio*len(df)\n",
    "    sum_of_train_data = 0\n",
    "    user_ids =[]\n",
    "\n",
    "    for user_id, count in users:\n",
    "        sum_of_train_data += count\n",
    "        if max_train_data_len < sum_of_train_data:\n",
    "            break\n",
    "        user_ids.append(user_id)\n",
    "    \n",
    "    #train = df[df['userID'] == df['userID'].shift(-1)]\n",
    "    #valid = df[df['userID'] != df['userID'].shift(-1)]\n",
    "    \n",
    "    train = df[df['userID'].isin(user_ids)]\n",
    "    valid = df[df['userID'].isin(user_ids) == False]\n",
    "    \n",
    "    valid = valid[valid['userID'] != valid['userID'].shift(-1)]\n",
    "    \n",
    "    X_train = train.drop(['answerCode', 'Timestamp', 'datetime'], axis = 1)\n",
    "    y_train = train[['answerCode']]\n",
    "    X_valid = valid.drop(['answerCode', 'Timestamp', 'datetime'], axis = 1)\n",
    "    y_valid = valid[['answerCode']]\n",
    "    \n",
    "    features = [ col for col in X_train.columns] \n",
    "\n",
    "    cat_idxs = [ i for i, f in enumerate(features) if f in categorical_columns]\n",
    "\n",
    "    cat_dims = [ categorical_dims[f] for i, f in enumerate(features) if f in categorical_columns]\n",
    "    \n",
    "    return X_train, y_train, X_valid, y_valid, cat_idxs, cat_dims, features, categorical_columns\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = feature_engineering_base(df)\n",
    "df = elo(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_valid, y_valid, cat_idxs, cat_dims, features, categorical_columns = custom_split_and_encoding(df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = TabNetClassifier(\n",
    "    # n_d = 64,\n",
    "    # n_a = 64\n",
    "    cat_idxs=cat_idxs,\n",
    "    cat_dims=cat_dims,\n",
    "    cat_emb_dim=10,\n",
    "    optimizer_fn=torch.optim.Adam,\n",
    "    optimizer_params=dict(lr=1e-2),\n",
    "    scheduler_params={\"step_size\":50,\n",
    "                        \"gamma\":0.9},\n",
    "    scheduler_fn=torch.optim.lr_scheduler.StepLR,\n",
    "    mask_type='sparsemax', # \"sparsemax\", entmax\n",
    "    verbose=1,\n",
    "    device_name='cuda'\n",
    ")\n",
    "\n",
    "clf.fit(\n",
    "    X_train=X_train[features].values, y_train=y_train.values.flatten(),\n",
    "    eval_set=[(X_train[features].values, y_train.values.flatten()), (X_valid[features].values, y_valid.values.flatten())],\n",
    "    eval_name=['train', 'valid'],\n",
    "    eval_metric=['accuracy', 'auc'],\n",
    "    max_epochs=41,\n",
    "    patience=10,\n",
    "    batch_size=14598,\n",
    "    virtual_batch_size=4430,\n",
    "    drop_last=False,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test Data 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(test_data_path)\n",
    "\n",
    "test_df = feature_engineering_base(test_df)\n",
    "test_df = elo(test_df)\n",
    "\n",
    "for col in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    test_df[col] = le.fit_transform(test_df[col].values)\n",
    "\n",
    "y_test = test_df['answerCode'].values\n",
    "X_test = test_df.drop(['answerCode', 'Timestamp', 'datetime'], axis=1)\n",
    "\n",
    "#FEATS = [col for col in X_test.columns]\n",
    "test = X_test[X_test['userID'] != X_test['userID'].shift(-1)].to_numpy()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = clf.predict_proba(test)\n",
    "total_preds = preds[:, 1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "output_dir = 'output/'\n",
    "write_path = os.path.join(output_dir, \"submission.csv\")\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "with open(write_path, 'w', encoding='utf8') as w:\n",
    "    print(\"writing prediction : {}\".format(write_path))\n",
    "    w.write(\"id,prediction\\n\")\n",
    "    for id, p in enumerate(total_preds):\n",
    "        w.write('{},{}\\n'.format(id,p))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
