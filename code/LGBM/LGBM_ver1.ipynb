{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0514deab",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1.라이브러리 세팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02e75786",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import pdb\n",
    "import wandb\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import KFold, GroupKFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f79608fc-5901-4db6-af50-8aee1b32f288",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e907585",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.52 s, sys: 232 ms, total: 2.76 s\n",
      "Wall time: 2.75 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dtype = {\n",
    "    'userID': 'int16',\n",
    "    'answerCode': 'int8',\n",
    "    'KnowledgeTag': 'int16'\n",
    "}   \n",
    "\n",
    "# 데이터 경로 맞춰주세요!\n",
    "# 혹시 코랩환경을 사용하신다면 왼쪽 폴더모양 아이콘을 눌러 \"train_data.csv\"를 드래그&드롭으로 업로드한 후 사용해주세요\n",
    "DATA_PATH = '/opt/ml/input/data/'\n",
    "df = pd.read_csv(DATA_PATH+'train_data.csv' , dtype=dtype, parse_dates=['Timestamp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62621b6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 2. 피쳐 엔지니어링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ec9562a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "day_dict = {'Tuesday': 0,\n",
    " 'Thursday': 1,\n",
    " 'Monday': 2,\n",
    " 'Saturday': 3,\n",
    " 'Friday': 4,\n",
    " 'Wednesday': 5,\n",
    " 'Sunday': 6}\n",
    "\n",
    "def feature_engineering(df):\n",
    "    df = df.copy()\n",
    "    #유저별 시퀀스를 고려하기 위해 아래와 같이 정렬\n",
    "    df.sort_values(by=['userID','Timestamp'], inplace=True)\n",
    "    \n",
    "    #유저들의 문제 풀이수, 정답 수, 정답률을 시간순으로 누적해서 계산\n",
    "    df['user_correct_answer'] = df.groupby('userID')['answerCode'].transform(lambda x: x.cumsum().shift(1))\n",
    "    df['user_total_answer'] = df.groupby('userID')['answerCode'].cumcount()\n",
    "    df['user_acc'] = df['user_correct_answer']/df['user_total_answer']\n",
    "    \n",
    "    # 문제 푸는데 걸린 시간\n",
    "    # 10분이상 시간소요는 새로운 문제집을 시작한 것으로 판단\n",
    "    diff = df.loc[:, ['userID', 'Timestamp']].groupby('userID').diff().fillna(pd.Timedelta(seconds=0))\n",
    "    diff = diff.fillna(pd.Timedelta(seconds=0))\n",
    "    diff = diff['Timestamp'].apply(lambda x: x.total_seconds())\n",
    "    df['elapsed'] = diff\n",
    "    df['elapsed'] = df['elapsed'].apply(lambda x: 0 if x>= 600 else x)\n",
    "    # 문제 푸는데 걸린 누적 시간\n",
    "    df['elapsed_cumsum'] = df.groupby('userID')['elapsed'].cumsum()\n",
    "    #문제 푸는데 걸린 시간의 중앙값\n",
    "    elapsed_med = df.groupby('userID')['elapsed'].agg(['median'])\n",
    "    elapsed_med.columns = ['elapsed_med']\n",
    "    #시간 쪼개기 + 요일\n",
    "    df['month'] = pd.to_datetime(df.Timestamp).dt.month\n",
    "    df['day'] = pd.to_datetime(df.Timestamp).dt.day\n",
    "    df['hour'] = pd.to_datetime(df.Timestamp).dt.hour\n",
    "    df['dayname'] = pd.to_datetime(df.Timestamp).dt.day_name().map(day_dict)\n",
    "    \n",
    "    #대분류/유저\n",
    "    df['bigclass'] = df['testId'].apply(lambda x : x[2]).astype(int)\n",
    "    # 유저별 대분류 문제 풀이시간\n",
    "    bigclasstime = df.groupby(['userID','bigclass']).agg({'elapsed' : 'mean'}).reset_index()\n",
    "\n",
    "    # 유저별 대분류 문제 횟수\n",
    "    bigclassCount = df.groupby(['userID','bigclass'])['answerCode'].count().reset_index()\n",
    "    # 유저별 대분류 문제 정답 횟수\n",
    "    bigclasssum = df.groupby(['userID','bigclass'])['answerCode'].sum().reset_index()\n",
    "    v = bigclasssum['answerCode'].values/bigclassCount['answerCode'].values\n",
    "    bigclasstime['bigclass_acc'] = v\n",
    "    bigclasstime['bigclass_count']  = bigclassCount['answerCode'].values\n",
    "    bigclasstime['bigclass_sum'] = bigclasssum['answerCode'].values\n",
    "    bigclass = bigclasstime.rename(columns = {'elapsed' : 'bigclasstime'})\n",
    "    df = pd.merge(df,bigclass, on = ['userID','bigclass'],how = 'left')\n",
    "\n",
    "\n",
    "    \n",
    "    # testId와 KnowledgeTag의 전체 정답률은 한번에 계산\n",
    "    # 아래 데이터는 제출용 데이터셋에 대해서도 재사용\n",
    "    correct_t = df.groupby(['testId'])['answerCode'].agg(['mean', 'std', 'sum'])\n",
    "    correct_t.columns = [\"test_mean\", \"test_std\", 'test_sum']\n",
    "    correct_k = df.groupby(['KnowledgeTag'])['answerCode'].agg(['mean', 'std', 'sum'])\n",
    "    correct_k.columns = [\"tag_mean\", 'tag_std', 'tag_sum']\n",
    "\n",
    "    df = pd.merge(df, correct_t, on=['testId'], how=\"left\")\n",
    "    df = pd.merge(df, correct_k, on=['KnowledgeTag'], how=\"left\")\n",
    "    df = pd.merge(df, elapsed_med, on =['userID'], how = 'left')\n",
    "    df.fillna(0,inplace = True)\n",
    "    # df.sort_values(by=['userID','Timestamp'], inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23d827c9-9648-4897-aa1d-259180ad83f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#elo 함수\n",
    "def elo(df):\n",
    "    def get_new_theta(is_good_answer, beta, left_asymptote, theta, nb_previous_answers):\n",
    "        return theta + learning_rate_theta(nb_previous_answers) * (\n",
    "            is_good_answer - probability_of_good_answer(theta, beta, left_asymptote)\n",
    "        )\n",
    "\n",
    "    def get_new_beta(is_good_answer, beta, left_asymptote, theta, nb_previous_answers):\n",
    "        return beta - learning_rate_beta(nb_previous_answers) * (\n",
    "            is_good_answer - probability_of_good_answer(theta, beta, left_asymptote)\n",
    "        )\n",
    "\n",
    "    def learning_rate_theta(nb_answers):\n",
    "        return max(0.3 / (1 + 0.01 * nb_answers), 0.04)\n",
    "\n",
    "    def learning_rate_beta(nb_answers):\n",
    "        return 1 / (1 + 0.05 * nb_answers)\n",
    "\n",
    "    def probability_of_good_answer(theta, beta, left_asymptote):\n",
    "        return left_asymptote + (1 - left_asymptote) * sigmoid(theta - beta)\n",
    "\n",
    "    def sigmoid(x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def estimate_parameters(answers_df, granularity_feature_name=\"assessmentItemID\"):\n",
    "        item_parameters = {\n",
    "            granularity_feature_value: {\"beta\": 0, \"nb_answers\": 0}\n",
    "            for granularity_feature_value in np.unique(\n",
    "                answers_df[granularity_feature_name]\n",
    "            )\n",
    "        }\n",
    "        student_parameters = {\n",
    "            student_id: {\"theta\": 0, \"nb_answers\": 0}\n",
    "            for student_id in np.unique(answers_df.userID)\n",
    "        }\n",
    "\n",
    "        print(\"Parameter estimation is starting...\", flush=True)\n",
    "\n",
    "        for student_id, item_id, left_asymptote, answered_correctly in tqdm(\n",
    "            zip(\n",
    "                answers_df.userID.values,\n",
    "                answers_df[granularity_feature_name].values,\n",
    "                answers_df.left_asymptote.values,\n",
    "                answers_df.answerCode.values,\n",
    "            ),\n",
    "            total=len(answers_df),\n",
    "        ):\n",
    "            theta = student_parameters[student_id][\"theta\"]\n",
    "            beta = item_parameters[item_id][\"beta\"]\n",
    "\n",
    "            item_parameters[item_id][\"beta\"] = get_new_beta(\n",
    "                answered_correctly,\n",
    "                beta,\n",
    "                left_asymptote,\n",
    "                theta,\n",
    "                item_parameters[item_id][\"nb_answers\"],\n",
    "            )\n",
    "            student_parameters[student_id][\"theta\"] = get_new_theta(\n",
    "                answered_correctly,\n",
    "                beta,\n",
    "                left_asymptote,\n",
    "                theta,\n",
    "                student_parameters[student_id][\"nb_answers\"],\n",
    "            )\n",
    "\n",
    "            item_parameters[item_id][\"nb_answers\"] += 1\n",
    "            student_parameters[student_id][\"nb_answers\"] += 1\n",
    "\n",
    "        print(f\"Theta & beta estimations on {granularity_feature_name} are completed.\")\n",
    "        return student_parameters, item_parameters\n",
    "\n",
    "    def gou_func(theta, beta):\n",
    "        return 1 / (1 + np.exp(-(theta - beta)))\n",
    "\n",
    "    df[\"left_asymptote\"] = 0\n",
    "\n",
    "    print(f\"Dataset of shape {df.shape}\")\n",
    "    print(f\"Columns are {list(df.columns)}\")\n",
    "\n",
    "    student_parameters, item_parameters = estimate_parameters(df)\n",
    "\n",
    "    prob = [\n",
    "        gou_func(student_parameters[student][\"theta\"], item_parameters[item][\"beta\"])\n",
    "        for student, item in zip(df.userID.values, df.assessmentItemID.values)\n",
    "    ]\n",
    "\n",
    "    df[\"elo\"] = prob\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "545ba563",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset of shape (2266586, 28)\n",
      "Columns are ['userID', 'assessmentItemID', 'testId', 'answerCode', 'Timestamp', 'KnowledgeTag', 'user_correct_answer', 'user_total_answer', 'user_acc', 'elapsed', 'elapsed_cumsum', 'month', 'day', 'hour', 'dayname', 'bigclass', 'bigclasstime', 'bigclass_acc', 'bigclass_count', 'bigclass_sum', 'test_mean', 'test_std', 'test_sum', 'tag_mean', 'tag_std', 'tag_sum', 'elapsed_med', 'left_asymptote']\n",
      "Parameter estimation is starting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2266586/2266586 [00:15<00:00, 150854.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theta & beta estimations on assessmentItemID are completed.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>assessmentItemID</th>\n",
       "      <th>testId</th>\n",
       "      <th>answerCode</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>KnowledgeTag</th>\n",
       "      <th>user_correct_answer</th>\n",
       "      <th>user_total_answer</th>\n",
       "      <th>user_acc</th>\n",
       "      <th>elapsed</th>\n",
       "      <th>...</th>\n",
       "      <th>bigclass_sum</th>\n",
       "      <th>test_mean</th>\n",
       "      <th>test_std</th>\n",
       "      <th>test_sum</th>\n",
       "      <th>tag_mean</th>\n",
       "      <th>tag_std</th>\n",
       "      <th>tag_sum</th>\n",
       "      <th>elapsed_med</th>\n",
       "      <th>left_asymptote</th>\n",
       "      <th>elo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>A060001001</td>\n",
       "      <td>A060000001</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-03-24 00:17:11</td>\n",
       "      <td>7224</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>274</td>\n",
       "      <td>0.947683</td>\n",
       "      <td>0.222749</td>\n",
       "      <td>1268</td>\n",
       "      <td>0.955022</td>\n",
       "      <td>0.207410</td>\n",
       "      <td>637</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.979350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>A060001002</td>\n",
       "      <td>A060000001</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-03-24 00:17:14</td>\n",
       "      <td>7225</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>274</td>\n",
       "      <td>0.947683</td>\n",
       "      <td>0.222749</td>\n",
       "      <td>1268</td>\n",
       "      <td>0.913187</td>\n",
       "      <td>0.281603</td>\n",
       "      <td>3040</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.970579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>A060001003</td>\n",
       "      <td>A060000001</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-03-24 00:17:22</td>\n",
       "      <td>7225</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>274</td>\n",
       "      <td>0.947683</td>\n",
       "      <td>0.222749</td>\n",
       "      <td>1268</td>\n",
       "      <td>0.913187</td>\n",
       "      <td>0.281603</td>\n",
       "      <td>3040</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.942168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>A060001004</td>\n",
       "      <td>A060000001</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-03-24 00:17:29</td>\n",
       "      <td>7225</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>274</td>\n",
       "      <td>0.947683</td>\n",
       "      <td>0.222749</td>\n",
       "      <td>1268</td>\n",
       "      <td>0.913187</td>\n",
       "      <td>0.281603</td>\n",
       "      <td>3040</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.972448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>A060001005</td>\n",
       "      <td>A060000001</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-03-24 00:17:36</td>\n",
       "      <td>7225</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>274</td>\n",
       "      <td>0.947683</td>\n",
       "      <td>0.222749</td>\n",
       "      <td>1268</td>\n",
       "      <td>0.913187</td>\n",
       "      <td>0.281603</td>\n",
       "      <td>3040</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.957230</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   userID assessmentItemID      testId  answerCode           Timestamp   \n",
       "0       0       A060001001  A060000001           1 2020-03-24 00:17:11  \\\n",
       "1       0       A060001002  A060000001           1 2020-03-24 00:17:14   \n",
       "2       0       A060001003  A060000001           1 2020-03-24 00:17:22   \n",
       "3       0       A060001004  A060000001           1 2020-03-24 00:17:29   \n",
       "4       0       A060001005  A060000001           1 2020-03-24 00:17:36   \n",
       "\n",
       "   KnowledgeTag  user_correct_answer  user_total_answer  user_acc  elapsed   \n",
       "0          7224                  0.0                  0       0.0      0.0  \\\n",
       "1          7225                  1.0                  1       1.0      3.0   \n",
       "2          7225                  2.0                  2       1.0      8.0   \n",
       "3          7225                  3.0                  3       1.0      7.0   \n",
       "4          7225                  4.0                  4       1.0      7.0   \n",
       "\n",
       "   ...  bigclass_sum  test_mean  test_std  test_sum  tag_mean   tag_std   \n",
       "0  ...           274   0.947683  0.222749      1268  0.955022  0.207410  \\\n",
       "1  ...           274   0.947683  0.222749      1268  0.913187  0.281603   \n",
       "2  ...           274   0.947683  0.222749      1268  0.913187  0.281603   \n",
       "3  ...           274   0.947683  0.222749      1268  0.913187  0.281603   \n",
       "4  ...           274   0.947683  0.222749      1268  0.913187  0.281603   \n",
       "\n",
       "   tag_sum  elapsed_med  left_asymptote       elo  \n",
       "0      637         14.0               0  0.979350  \n",
       "1     3040         14.0               0  0.970579  \n",
       "2     3040         14.0               0  0.942168  \n",
       "3     3040         14.0               0  0.972448  \n",
       "4     3040         14.0               0  0.957230  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = feature_engineering(df)\n",
    "df2 = elo(df2)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba674f0",
   "metadata": {},
   "source": [
    "## 3. Train/Test 데이터 셋 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "75323e88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 사용할 Feature 설정\n",
    "FEATS = ['KnowledgeTag', \n",
    "         'user_correct_answer', \n",
    "         'user_total_answer', \n",
    "         'user_acc',\n",
    "         'test_mean', \n",
    "         'test_sum', \n",
    "         'tag_mean',\n",
    "         'tag_sum',\n",
    "         'elapsed',\n",
    "         'elapsed_cumsum',\n",
    "         'month',\n",
    "         'day',\n",
    "         'hour',\n",
    "         'dayname',\n",
    "         'elapsed_med',\n",
    "         'bigclass',\n",
    "         'bigclasstime',\n",
    "         'bigclass_acc',\n",
    "         'bigclass_sum',\n",
    "         'bigclass_count',\n",
    "         'elo'\n",
    "             ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "93024444-0fd9-4574-ae5a-c0fe57c42876",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ###\n",
    "# wandb.init(project=\"LGBM\",entity = 'recommy',name = 'bigclass')\n",
    "# ###"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1f9aa4-6ef4-4f3f-89c9-5a69e7dd388f",
   "metadata": {},
   "source": [
    "## 3.5 GroupKfold\n",
    "\n",
    "### 챗gpt\n",
    "DKT(Dynamic Key-Value Memory Networks for Knowledge Tracing)는 학생들의 학습 이력을 시계열 데이터로 다루는 문제입니다. 시계열 데이터를 다룰 때 KFold 또는 GroupKFold를 적용할 수 있습니다.\n",
    "\n",
    "만약 KFold를 적용하려면, 각 Fold에서 학생의 학습 이력이 시간순으로 잘 분리되어야 합니다. 이렇게 해야 모델이 이전 Fold에서 학습한 데이터와 다음 Fold에서 평가할 데이터 간의 시간적인 일관성을 유지할 수 있습니다.\n",
    "\n",
    "하지만 대개 학생의 학습 이력은 시간순으로 연속적으로 기록되어 있으므로, Fold를 나눌 때 시간적 일관성을 유지하기 어려울 수 있습니다. 따라서, 이런 경우 GroupKFold를 적용하는 것이 좋습니다. GroupKFold는 Fold를 나눌 때 각 Fold에서 특정 그룹(여기서는 학생)이 포함되지 않도록 보장합니다. 그룹별로 나누어진 Fold를 사용하여 모델을 학습하고 평가하면 시간적 일관성을 유지할 수 있습니다.\n",
    "\n",
    "따라서, DKT 같은 시계열 데이터를 다루는 문제에서는 일반적으로 GroupKFold를 사용하는 것이 더 적절합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c89a38a2-c827-4bd5-a46f-d1c67233dd23",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# X, y 값 분리\n",
    "# y_train = train['answerCode']\n",
    "# train = train.drop(['answerCode'], axis=1)\n",
    "\n",
    "# y_test = test['answerCode']\n",
    "# test = test.drop(['answerCode'], axis=1)\n",
    "\n",
    "y_train = df2['answerCode']\n",
    "train = df2.drop(['answerCode'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7e94d3-b245-4669-8fe9-eb2f306ad3ad",
   "metadata": {},
   "source": [
    "## 4. 훈련 및 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2f4f84c1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 1188378, number of negative: 624897\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017312 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3456\n",
      "[LightGBM] [Info] Number of data points in the train set: 1813275, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.655377 -> initscore=0.642758\n",
      "[LightGBM] [Info] Start training from score 0.642758\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.455532\tvalid_1's binary_logloss: 0.460321\n",
      "[200]\ttraining's binary_logloss: 0.451581\tvalid_1's binary_logloss: 0.458889\n",
      "[300]\ttraining's binary_logloss: 0.448648\tvalid_1's binary_logloss: 0.458173\n",
      "[400]\ttraining's binary_logloss: 0.44629\tvalid_1's binary_logloss: 0.457931\n",
      "[500]\ttraining's binary_logloss: 0.444215\tvalid_1's binary_logloss: 0.457765\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's binary_logloss: 0.444215\tvalid_1's binary_logloss: 0.457765\n",
      "--------------------K-fold 0--------------------\n",
      "VALID AUC : 0.8431646466330613 ACC : 0.7889043063150906\n",
      "\n",
      "[LightGBM] [Info] Number of positive: 1186072, number of negative: 627191\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017549 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3451\n",
      "[LightGBM] [Info] Number of data points in the train set: 1813263, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.654109 -> initscore=0.637151\n",
      "[LightGBM] [Info] Start training from score 0.637151\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.456296\tvalid_1's binary_logloss: 0.456682\n",
      "[200]\ttraining's binary_logloss: 0.452392\tvalid_1's binary_logloss: 0.455312\n",
      "[300]\ttraining's binary_logloss: 0.449618\tvalid_1's binary_logloss: 0.454647\n",
      "[400]\ttraining's binary_logloss: 0.447402\tvalid_1's binary_logloss: 0.45432\n",
      "[500]\ttraining's binary_logloss: 0.445188\tvalid_1's binary_logloss: 0.454042\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's binary_logloss: 0.445188\tvalid_1's binary_logloss: 0.454042\n",
      "--------------------K-fold 1--------------------\n",
      "VALID AUC : 0.8437168202435292 ACC : 0.7911445040291359\n",
      "\n",
      "[LightGBM] [Info] Number of positive: 1184533, number of negative: 628730\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017744 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3453\n",
      "[LightGBM] [Info] Number of data points in the train set: 1813263, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.653260 -> initscore=0.633402\n",
      "[LightGBM] [Info] Start training from score 0.633402\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.455676\tvalid_1's binary_logloss: 0.459953\n",
      "[200]\ttraining's binary_logloss: 0.451803\tvalid_1's binary_logloss: 0.458475\n",
      "[300]\ttraining's binary_logloss: 0.448844\tvalid_1's binary_logloss: 0.457732\n",
      "[400]\ttraining's binary_logloss: 0.446656\tvalid_1's binary_logloss: 0.457392\n",
      "[500]\ttraining's binary_logloss: 0.44456\tvalid_1's binary_logloss: 0.457146\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's binary_logloss: 0.44456\tvalid_1's binary_logloss: 0.457146\n",
      "--------------------K-fold 2--------------------\n",
      "VALID AUC : 0.8406454232607263 ACC : 0.7891635765227002\n",
      "\n",
      "[LightGBM] [Info] Number of positive: 1187795, number of negative: 625472\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.017319 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3453\n",
      "[LightGBM] [Info] Number of data points in the train set: 1813267, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.655058 -> initscore=0.641347\n",
      "[LightGBM] [Info] Start training from score 0.641347\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.455436\tvalid_1's binary_logloss: 0.461205\n",
      "[200]\ttraining's binary_logloss: 0.451416\tvalid_1's binary_logloss: 0.459925\n",
      "[300]\ttraining's binary_logloss: 0.448553\tvalid_1's binary_logloss: 0.459184\n",
      "[400]\ttraining's binary_logloss: 0.446254\tvalid_1's binary_logloss: 0.458846\n",
      "[500]\ttraining's binary_logloss: 0.444059\tvalid_1's binary_logloss: 0.458708\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's binary_logloss: 0.444059\tvalid_1's binary_logloss: 0.458708\n",
      "--------------------K-fold 3--------------------\n",
      "VALID AUC : 0.8422377161580505 ACC : 0.7888992078426009\n",
      "\n",
      "[LightGBM] [Info] Number of positive: 1186042, number of negative: 627234\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015533 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3457\n",
      "[LightGBM] [Info] Number of data points in the train set: 1813276, number of used features: 16\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.654088 -> initscore=0.637057\n",
      "[LightGBM] [Info] Start training from score 0.637057\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's binary_logloss: 0.456008\tvalid_1's binary_logloss: 0.458423\n",
      "[200]\ttraining's binary_logloss: 0.452173\tvalid_1's binary_logloss: 0.457036\n",
      "[300]\ttraining's binary_logloss: 0.449364\tvalid_1's binary_logloss: 0.456436\n",
      "[400]\ttraining's binary_logloss: 0.447024\tvalid_1's binary_logloss: 0.456146\n",
      "[500]\ttraining's binary_logloss: 0.444911\tvalid_1's binary_logloss: 0.456005\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's binary_logloss: 0.444911\tvalid_1's binary_logloss: 0.456005\n",
      "--------------------K-fold 4--------------------\n",
      "VALID AUC : 0.842280841041693 ACC : 0.7903686219143632\n",
      "\n",
      "k-fold valid auc: 0.8424090894674121 , k-fold valid acc: 0.7896960433247782\n"
     ]
    }
   ],
   "source": [
    "# lgb_train = lgb.Dataset(train[FEATS], y_train)\n",
    "# lgb_test = lgb.Dataset(test[FEATS], y_test)\n",
    "\n",
    "groups = train['userID']\n",
    "fold_len = 5\n",
    "gkf = GroupKFold(n_splits = 5)\n",
    "\n",
    "model_lst = []\n",
    "result_auc = 0\n",
    "result_acc = 0\n",
    "for i,(train_index, test_index) in enumerate(gkf.split(train,y_train,groups= groups)):\n",
    "    lgb_train = lgb.Dataset(train.iloc[train_index][FEATS],y_train.iloc[train_index])\n",
    "    lgb_test = lgb.Dataset(train.iloc[test_index][FEATS],y_train.iloc[test_index])\n",
    "    \n",
    "    random.seed(42)\n",
    "    model_lst.append(lgb.train(\n",
    "    {'objective': 'binary'}, \n",
    "    lgb_train,\n",
    "    valid_sets=[lgb_train,lgb_test],\n",
    "    verbose_eval=100,\n",
    "    early_stopping_rounds=100,\n",
    "    num_boost_round=500,\n",
    "    # callbacks=[wandb.lightgbm.wandb_callback()]\n",
    "))\n",
    "    # wandb.lightgbm.log_summary(model_lst[i], save_model_checkpoint=True)\n",
    "\n",
    "    preds = model_lst[i].predict(train.iloc[test_index][FEATS])\n",
    "    acc = accuracy_score(y_train.iloc[test_index], np.where(preds >= 0.5, 1, 0))\n",
    "    auc = roc_auc_score(y_train.iloc[test_index], preds)\n",
    "    result_auc+=auc\n",
    "    result_acc+=acc\n",
    "    # wandb.log({\"valid_accuracy\": acc})\n",
    "    # wandb.log({\"valid_roc_auc\": auc})\n",
    "\n",
    "    print(f\"--------------------K-fold {i}--------------------\")\n",
    "    print(f'VALID AUC : {auc} ACC : {acc}\\n')\n",
    "\n",
    "print(f\"k-fold valid auc: {result_auc/fold_len} , k-fold valid acc: {result_acc/fold_len}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b39ebd12-439a-4ef5-bfa4-8842d42614be",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "29ca5bd2-2301-4d8d-930a-f74ae957cfe3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset of shape (260114, 28)\n",
      "Columns are ['userID', 'assessmentItemID', 'testId', 'answerCode', 'Timestamp', 'KnowledgeTag', 'user_correct_answer', 'user_total_answer', 'user_acc', 'elapsed', 'elapsed_cumsum', 'month', 'day', 'hour', 'dayname', 'bigclass', 'bigclasstime', 'bigclass_acc', 'bigclass_count', 'bigclass_sum', 'test_mean', 'test_std', 'test_sum', 'tag_mean', 'tag_std', 'tag_sum', 'elapsed_med', 'left_asymptote']\n",
      "Parameter estimation is starting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 260114/260114 [00:01<00:00, 142342.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Theta & beta estimations on assessmentItemID are completed.\n"
     ]
    }
   ],
   "source": [
    "# LOAD TESTDATA\n",
    "test_df = pd.read_csv(DATA_PATH+'test_data.csv' , dtype=dtype, parse_dates=['Timestamp'])\n",
    "test_df = test_df.sort_values(by=['userID', 'Timestamp']).reset_index(drop=True)\n",
    "# test_csv_file_path = os.path.join(DATA_PATH, 'test_data.csv')\n",
    "# test_df = pd.read_csv(test_csv_file_path)\n",
    "\n",
    "# FEATURE ENGINEERING\n",
    "test_df = feature_engineering(test_df)\n",
    "test_df = elo(test_df)\n",
    "\n",
    "# # LEAVE LAST INTERACTION ONLY\n",
    "# test_df = test_df[test_df['userID'] != test_df['userID'].shift(-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "54cb300b-3110-4040-9000-11d292aa83fd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing prediction : /opt/ml/input/output/LGBM/total_lgbm2.csv\n"
     ]
    }
   ],
   "source": [
    "# SAVE OUTPUT\n",
    "output_dir = '/opt/ml/input/output/LGBM'\n",
    "write_path = os.path.join(output_dir, \"total_lgbm2.csv\")\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "with open(write_path, 'w', encoding='utf8') as w:\n",
    "    print(\"writing prediction : {}\".format(write_path))\n",
    "    w.write(\"id,prediction\\n\")\n",
    "    for id, p in enumerate(total_preds):\n",
    "        w.write('{},{}\\n'.format(id,p))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d25f633e-2d03-4ebb-aaa3-ec47747fae9a",
   "metadata": {},
   "source": [
    "## TEST_DATSET의 -2번째 값 예측 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "fa3041e9-b458-4ba9-9504-f2009c698489",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# LEAVE LAST INTERACTION ONLY\n",
    "test_df = test_df[test_df['userID'] != test_df['userID'].shift(-2)]\n",
    "test_df = test_df[test_df['userID'] != test_df['userID'].shift(1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "43427893-c64f-4933-8714-47e365d3121c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userID</th>\n",
       "      <th>assessmentItemID</th>\n",
       "      <th>testId</th>\n",
       "      <th>answerCode</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>KnowledgeTag</th>\n",
       "      <th>user_correct_answer</th>\n",
       "      <th>user_total_answer</th>\n",
       "      <th>user_acc</th>\n",
       "      <th>elapsed</th>\n",
       "      <th>...</th>\n",
       "      <th>bigclass_sum</th>\n",
       "      <th>test_mean</th>\n",
       "      <th>test_std</th>\n",
       "      <th>test_sum</th>\n",
       "      <th>tag_mean</th>\n",
       "      <th>tag_std</th>\n",
       "      <th>tag_sum</th>\n",
       "      <th>elapsed_med</th>\n",
       "      <th>left_asymptote</th>\n",
       "      <th>elo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1034</th>\n",
       "      <td>3</td>\n",
       "      <td>A050133007</td>\n",
       "      <td>A050000133</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-10-26 13:13:11</td>\n",
       "      <td>5289</td>\n",
       "      <td>717.0</td>\n",
       "      <td>1034</td>\n",
       "      <td>0.693424</td>\n",
       "      <td>19.0</td>\n",
       "      <td>...</td>\n",
       "      <td>563</td>\n",
       "      <td>0.661765</td>\n",
       "      <td>0.490209</td>\n",
       "      <td>90</td>\n",
       "      <td>0.542662</td>\n",
       "      <td>0.505845</td>\n",
       "      <td>159</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.155744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1705</th>\n",
       "      <td>4</td>\n",
       "      <td>A070146007</td>\n",
       "      <td>A070000146</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-12-27 02:47:31</td>\n",
       "      <td>9080</td>\n",
       "      <td>464.0</td>\n",
       "      <td>669</td>\n",
       "      <td>0.693572</td>\n",
       "      <td>40.0</td>\n",
       "      <td>...</td>\n",
       "      <td>298</td>\n",
       "      <td>0.740385</td>\n",
       "      <td>0.539601</td>\n",
       "      <td>77</td>\n",
       "      <td>0.565693</td>\n",
       "      <td>0.552442</td>\n",
       "      <td>155</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.871477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3022</th>\n",
       "      <td>13</td>\n",
       "      <td>A070111007</td>\n",
       "      <td>A070000111</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-12-27 04:35:01</td>\n",
       "      <td>9660</td>\n",
       "      <td>914.0</td>\n",
       "      <td>1315</td>\n",
       "      <td>0.695057</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>190</td>\n",
       "      <td>0.417857</td>\n",
       "      <td>0.501291</td>\n",
       "      <td>117</td>\n",
       "      <td>0.446753</td>\n",
       "      <td>0.518307</td>\n",
       "      <td>172</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.279952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4282</th>\n",
       "      <td>17</td>\n",
       "      <td>A090064005</td>\n",
       "      <td>A090000064</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-10-30 05:47:22</td>\n",
       "      <td>2611</td>\n",
       "      <td>1030.0</td>\n",
       "      <td>1258</td>\n",
       "      <td>0.818760</td>\n",
       "      <td>106.0</td>\n",
       "      <td>...</td>\n",
       "      <td>380</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.530957</td>\n",
       "      <td>30</td>\n",
       "      <td>0.514286</td>\n",
       "      <td>0.531415</td>\n",
       "      <td>36</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.660142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4669</th>\n",
       "      <td>26</td>\n",
       "      <td>A060135006</td>\n",
       "      <td>A060000135</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-10-23 11:44:01</td>\n",
       "      <td>1422</td>\n",
       "      <td>293.0</td>\n",
       "      <td>385</td>\n",
       "      <td>0.761039</td>\n",
       "      <td>16.0</td>\n",
       "      <td>...</td>\n",
       "      <td>272</td>\n",
       "      <td>0.678571</td>\n",
       "      <td>0.479048</td>\n",
       "      <td>133</td>\n",
       "      <td>0.602767</td>\n",
       "      <td>0.493836</td>\n",
       "      <td>305</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.708387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260051</th>\n",
       "      <td>7395</td>\n",
       "      <td>A040122004</td>\n",
       "      <td>A040000122</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-09-08 02:05:18</td>\n",
       "      <td>2102</td>\n",
       "      <td>7.0</td>\n",
       "      <td>22</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.753846</td>\n",
       "      <td>0.443653</td>\n",
       "      <td>147</td>\n",
       "      <td>0.705263</td>\n",
       "      <td>0.456726</td>\n",
       "      <td>201</td>\n",
       "      <td>2.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.297233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260066</th>\n",
       "      <td>7404</td>\n",
       "      <td>A030111004</td>\n",
       "      <td>A030000111</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-10-13 09:47:31</td>\n",
       "      <td>7636</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>22.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.356895</td>\n",
       "      <td>156</td>\n",
       "      <td>0.834661</td>\n",
       "      <td>0.377186</td>\n",
       "      <td>419</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.722634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260081</th>\n",
       "      <td>7416</td>\n",
       "      <td>A050193003</td>\n",
       "      <td>A050000193</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-10-04 02:44:17</td>\n",
       "      <td>10402</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.479372</td>\n",
       "      <td>75</td>\n",
       "      <td>0.792517</td>\n",
       "      <td>0.446234</td>\n",
       "      <td>233</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.166592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260096</th>\n",
       "      <td>7417</td>\n",
       "      <td>A050193003</td>\n",
       "      <td>A050000193</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-09-06 13:08:54</td>\n",
       "      <td>10402</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>31.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.479372</td>\n",
       "      <td>75</td>\n",
       "      <td>0.792517</td>\n",
       "      <td>0.446234</td>\n",
       "      <td>233</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.072752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>260112</th>\n",
       "      <td>7439</td>\n",
       "      <td>A040130004</td>\n",
       "      <td>A040000130</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-10-14 23:09:31</td>\n",
       "      <td>8244</td>\n",
       "      <td>10.0</td>\n",
       "      <td>14</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>89.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>0.604762</td>\n",
       "      <td>0.499738</td>\n",
       "      <td>127</td>\n",
       "      <td>0.725490</td>\n",
       "      <td>0.476214</td>\n",
       "      <td>111</td>\n",
       "      <td>19.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.760312</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>744 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        userID assessmentItemID      testId  answerCode           Timestamp   \n",
       "1034         3       A050133007  A050000133           0 2020-10-26 13:13:11  \\\n",
       "1705         4       A070146007  A070000146           1 2020-12-27 02:47:31   \n",
       "3022        13       A070111007  A070000111           1 2020-12-27 04:35:01   \n",
       "4282        17       A090064005  A090000064           1 2020-10-30 05:47:22   \n",
       "4669        26       A060135006  A060000135           0 2020-10-23 11:44:01   \n",
       "...        ...              ...         ...         ...                 ...   \n",
       "260051    7395       A040122004  A040000122           0 2020-09-08 02:05:18   \n",
       "260066    7404       A030111004  A030000111           1 2020-10-13 09:47:31   \n",
       "260081    7416       A050193003  A050000193           0 2020-10-04 02:44:17   \n",
       "260096    7417       A050193003  A050000193           0 2020-09-06 13:08:54   \n",
       "260112    7439       A040130004  A040000130           1 2020-10-14 23:09:31   \n",
       "\n",
       "        KnowledgeTag  user_correct_answer  user_total_answer  user_acc   \n",
       "1034            5289                717.0               1034  0.693424  \\\n",
       "1705            9080                464.0                669  0.693572   \n",
       "3022            9660                914.0               1315  0.695057   \n",
       "4282            2611               1030.0               1258  0.818760   \n",
       "4669            1422                293.0                385  0.761039   \n",
       "...              ...                  ...                ...       ...   \n",
       "260051          2102                  7.0                 22  0.318182   \n",
       "260066          7636                  6.0                 13  0.461538   \n",
       "260081         10402                  7.0                 13  0.538462   \n",
       "260096         10402                  2.0                 13  0.153846   \n",
       "260112          8244                 10.0                 14  0.714286   \n",
       "\n",
       "        elapsed  ...  bigclass_sum  test_mean  test_std  test_sum  tag_mean   \n",
       "1034       19.0  ...           563   0.661765  0.490209        90  0.542662  \\\n",
       "1705       40.0  ...           298   0.740385  0.539601        77  0.565693   \n",
       "3022        2.0  ...           190   0.417857  0.501291       117  0.446753   \n",
       "4282      106.0  ...           380   0.625000  0.530957        30  0.514286   \n",
       "4669       16.0  ...           272   0.678571  0.479048       133  0.602767   \n",
       "...         ...  ...           ...        ...       ...       ...       ...   \n",
       "260051      2.0  ...             0   0.753846  0.443653       147  0.705263   \n",
       "260066     22.0  ...             1   0.866667  0.356895       156  0.834661   \n",
       "260081      9.0  ...             1   0.750000  0.479372        75  0.792517   \n",
       "260096     31.0  ...             1   0.750000  0.479372        75  0.792517   \n",
       "260112     89.0  ...            10   0.604762  0.499738       127  0.725490   \n",
       "\n",
       "         tag_std  tag_sum  elapsed_med  left_asymptote       elo  \n",
       "1034    0.505845      159         25.0               0  0.155744  \n",
       "1705    0.552442      155         38.0               0  0.871477  \n",
       "3022    0.518307      172         20.0               0  0.279952  \n",
       "4282    0.531415       36         34.5               0  0.660142  \n",
       "4669    0.493836      305         20.0               0  0.708387  \n",
       "...          ...      ...          ...             ...       ...  \n",
       "260051  0.456726      201          2.5               0  0.297233  \n",
       "260066  0.377186      419         15.0               0  0.722634  \n",
       "260081  0.446234      233         14.0               0  0.166592  \n",
       "260096  0.446234      233         21.0               0  0.072752  \n",
       "260112  0.476214      111         19.5               0  0.760312  \n",
       "\n",
       "[744 rows x 29 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "1b7d7df5-96c0-4384-a300-b2f6d441c9f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_df_y = test_df['answerCode']\n",
    "test_df_X = test_df.drop('answerCode',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "a13647f2-e416-4bfb-ad14-e8d6448b398b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inference = []\n",
    "for i in range(len(model_lst)):\n",
    "    inference.append(model_lst[i].predict(test_df_X[FEATS]))\n",
    "\n",
    "total_preds = np.mean(inference, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "721b7502-9d16-4527-84f8-b92a117933eb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST AUC : 0.8584815256431827 ACC : 0.7809139784946236\n",
      "\n"
     ]
    }
   ],
   "source": [
    "acc = accuracy_score(test_df_y, np.where(total_preds >= 0.5, 1, 0))\n",
    "auc = roc_auc_score(test_df_y, total_preds)\n",
    "\n",
    "print(f'TEST AUC : {auc} ACC : {acc}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d36ef48-1616-4fa7-96fa-9f2e812a3985",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "191.594px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
